import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { Command, MemorySaver, MessagesAnnotation, StateGraph, interrupt } from "@langchain/langgraph";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { ChatOpenAI } from "@langchain/openai";
import { stdin as input, stdout as output } from "node:process";
import { createInterface } from "node:readline/promises";
import { pushTool } from "./helpers/push";

/** ---- 0) Tools & Model ---- **/
const tools = [pushTool];
const toolNode = new ToolNode(tools);

const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
}).bindTools(tools);

/** ---- 1) Routing ---- **/
function shouldContinue({ messages }: typeof MessagesAnnotation.State) {
  console.log("shouldContinue");
  const last = messages[messages.length - 1] as AIMessage;
  if (last.tool_calls?.length) return "tools";
  return "__end__";
}

/** ---- 2) Model call ---- **/
async function callModel(state: typeof MessagesAnnotation.State) {
  console.log("callModel");
  const response = await model.invoke(state.messages);
  return { messages: [response] };
}

/** ---- 3) ì‚¬ìš©ì ì…ë ¥ 2ë²ˆì„ ìš”êµ¬ + ì…ë ¥ê°’ìœ¼ë¡œ pushTool ì‹¤í–‰ ---- **/
const nodeWithInterrupts = async (_state: typeof MessagesAnnotation.State) => {
  console.log("nodeWithInterrupts");
  // 1ì°¨ ì¤‘ë‹¨: name ì…ë ¥ ëŒ€ê¸°
  const name = interrupt({ prompt: "input your name" });
  // 2ì°¨ ì¤‘ë‹¨: email ì…ë ¥ ëŒ€ê¸°
  const email = interrupt({ prompt: "input your email" });
  return {
    messages: [
      new AIMessage({
        content: `âœ… push done for ${String(name)} <${String(email)}>}`,
      }),
    ],
  };
};

/** ---- 4) ê·¸ë˜í”„ ë¹Œë“œ ---- **/
const checkpointer = new MemorySaver(); // ì¬ê°œë¥¼ ìœ„í•´ í•„ìˆ˜
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("input", nodeWithInterrupts) // ì‚¬ìš©ì ì…ë ¥ 2ë²ˆ ë°›ëŠ” ë…¸ë“œ
  .addNode("agent", callModel)
  .addNode("tools", toolNode)
  .addEdge("__start__", "input") // ì‹œì‘ â†’ ì…ë ¥ ëŒ€ê¸° ë…¸ë“œ
  .addEdge("input", "agent") // ì…ë ¥ì„ ë§ˆì¹˜ë©´ ì—ì´ì „íŠ¸ë¡œ
  .addEdge("tools", "agent") // shouldContinue í•¨ìˆ˜ì— ë”°ë¼ íˆ´ ë…¸ë“œ ë˜ëŠ” ì¢…ë£Œ ë…¸ë“œë¡œ ì´ë™
  .addConditionalEdges("agent", shouldContinue); // ì—ì´ì „íŠ¸ ì‹¤í–‰ í›„ íˆ´ ì‹¤í–‰ ì—¬ë¶€ì— ë”°ë¼ íˆ´ ë…¸ë“œ ë˜ëŠ” ì¢…ë£Œ ë…¸ë“œë¡œ ì´ë™

const app = workflow.compile({ checkpointer });

/** ---- 5) í„°ë¯¸ë„ì—ì„œ ì…ë ¥ ë°›ì•„ ì¬ê°œí•˜ê¸° ---- **/
const thread_id = "demo-" + Math.random().toString(36).slice(2);

// í„°ë¯¸ë„ ì…ë ¥ í—¬í¼
const rl = createInterface({ input, output });
const ask = (q: string) => rl.question(q);

async function work(message: string) {
  // 1) ìµœì´ˆ ì‹¤í–‰ â†’ awaits ë…¸ë“œì—ì„œ interrupt(1)ì—ì„œ ë©ˆì¶¤
  for await (const _ of await app.stream({ messages: [new HumanMessage(message)] }, { configurable: { thread_id } })) {
    if (_.agent) {
      console.log(_.agent.messages[_.agent.messages.length - 1].content);
    }
  }

  // 2) ì²« ì¬ê°œ(name)
  const name = await ask("ğŸ“ name: ");
  for await (const _ of await app.stream(new Command({ resume: name }), { configurable: { thread_id } })) {
  }

  // 3) ë‘ ë²ˆì§¸ ì¬ê°œ(email)
  const email = await ask("ğŸ“§ email: ");
  for await (const _ of await app.stream(new Command({ resume: email }), { configurable: { thread_id } })) {
  }

  rl.close();

  // 4) ìµœì¢… ìƒíƒœ ì¶œë ¥
  const finalState = await app.getState({ configurable: { thread_id } });
  const last = finalState.values.messages[finalState.values.messages.length - 1] as AIMessage;
  console.log("\n=== FINAL ===\n" + last.content + "\n");
}

function main() {
  work("Would you push a notification to the user?");
}
main();
