import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { Command, MemorySaver, MessagesAnnotation, StateGraph, interrupt } from "@langchain/langgraph";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { ChatOpenAI } from "@langchain/openai";
import { stdin as input, stdout as output } from "node:process";
import { createInterface } from "node:readline/promises";
import { pushTool } from "./helpers/push";

/** ---- 0) Tools & Model ---- **/
const tools = [pushTool];
const toolNode = new ToolNode(tools);

const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
}).bindTools(tools);

/** ---- 1) Routing ---- **/
function shouldContinue({ messages }: typeof MessagesAnnotation.State) {
  const last = messages[messages.length - 1] as AIMessage;
  if (last.tool_calls?.length) return "tools";
  return "__end__";
}

/** ---- 2) Model call ---- **/
async function callModel(state: typeof MessagesAnnotation.State) {
  const response = await model.invoke(state.messages);
  return { messages: [response] };
}

/** ---- 3) ì‚¬ìš©ì ì…ë ¥ 2ë²ˆì„ ìš”êµ¬ + ì…ë ¥ê°’ìœ¼ë¡œ pushTool ì‹¤í–‰ ---- **/
const nodeWithInterrupts = async (_state: typeof MessagesAnnotation.State) => {
  // 1ì°¨ ì¤‘ë‹¨: name ì…ë ¥ ëŒ€ê¸°
  const name = interrupt({ prompt: "input your name" });
  // 2ì°¨ ì¤‘ë‹¨: email ì…ë ¥ ëŒ€ê¸°
  const email = interrupt({ prompt: "input your email" });

  return {
    messages: [
      new AIMessage({
        content: `âœ… push done for ${String(name)} <${String(email)}> \nresult: ${JSON.stringify(result)}`,
      }),
    ],
  };
};

/** ---- 4) ê·¸ë˜í”„ ë¹Œë“œ ---- **/
const checkpointer = new MemorySaver(); // ì¬ê°œë¥¼ ìœ„í•´ í•„ìˆ˜
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("awaits", nodeWithInterrupts) // ì‚¬ìš©ì ì…ë ¥ 2ë²ˆ ë°›ëŠ” ë…¸ë“œ
  .addNode("agent", callModel)
  .addNode("tools", toolNode)
  .addEdge("__start__", "awaits") // ì‹œì‘ â†’ ì…ë ¥ ëŒ€ê¸° ë…¸ë“œ
  .addEdge("awaits", "agent") // íˆ´ ì‹¤í–‰ê¹Œì§€ ëë‚˜ë©´ ì—ì´ì „íŠ¸ë¡œ
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue);

const app = workflow.compile({ checkpointer });

/** ---- 5) í„°ë¯¸ë„ì—ì„œ ì…ë ¥ ë°›ì•„ ì¬ê°œí•˜ê¸° ---- **/
const thread_id = "demo-" + Math.random().toString(36).slice(2);

// í„°ë¯¸ë„ ì…ë ¥ í—¬í¼
const rl = createInterface({ input, output });
const ask = (q: string) => rl.question(q);

// 5-1) ìµœì´ˆ ì‹¤í–‰ â†’ awaits ë…¸ë“œì—ì„œ interrupt(1)ì—ì„œ ë©ˆì¶¤
for await (const _ of await app.stream(
  { messages: [new HumanMessage("would you push a notification to the user?")] },
  { configurable: { thread_id } },
)) {
  /* ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ì†Œë¹„ë§Œ */
}

// 5-2) ì²« ì¬ê°œ(name)
const name = await ask("ğŸ“ name: ");
for await (const _ of await app.stream(new Command({ resume: name }), { configurable: { thread_id } })) {
  /* ì²« ì¬ê°œ ì²˜ë¦¬ */
}

// 5-3) ë‘ ë²ˆì§¸ ì¬ê°œ(email)
const email = await ask("ğŸ“§ email: ");
for await (const _ of await app.stream(new Command({ resume: email }), { configurable: { thread_id } })) {
  /* ë‘ ë²ˆì§¸ ì¬ê°œ ì²˜ë¦¬ (â†’ pushTool ì‹¤í–‰ë¨) */
}

await rl.close();

// 5-4) ìµœì¢… ìƒíƒœ ì¶œë ¥
const finalState = await app.getState({ configurable: { thread_id } });
const last = finalState.values.messages[finalState.values.messages.length - 1] as AIMessage;
console.log("\n=== FINAL ===\n" + last.content + "\n");
