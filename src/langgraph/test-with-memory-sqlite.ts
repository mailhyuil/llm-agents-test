import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { END, MessagesAnnotation, START, StateGraph } from "@langchain/langgraph";
import { SqliteSaver } from "@langchain/langgraph-checkpoint-sqlite";
import { ChatOpenAI } from "@langchain/openai";
import dotenv from "dotenv";

dotenv.config();

// Create a model
const model = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
});

// Define the agent function
async function callModel(state: typeof MessagesAnnotation.State) {
  const messages = state.messages;
  const response = await model.invoke(messages);
  return { messages: [response] };
}

// Define the conditional logic
function shouldContinue({ messages }: typeof MessagesAnnotation.State) {
  const lastMessage = messages[messages.length - 1] as AIMessage;
  if (lastMessage.tool_calls?.length) {
    return "tools";
  }
  return END;
}

// Create the workflow
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addConditionalEdges("agent", shouldContinue);

// Initialize SQLite checkpointer (ë” ê°„ë‹¨í•˜ê³  ì•ˆì •ì )
const checkpointer = new SqliteSaver("memory.db");
const threadId = "demo-" + Math.random().toString(36).slice(2);

// Compile the graph
const app = workflow.compile({ checkpointer });
const config = {
  configurable: {
    thread_id: threadId,
  },
};

// Main work function
async function work() {
  try {
    console.log("ğŸš€ LangGraph SQLite ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘");
    console.log(`ğŸ“ Thread ID: ${threadId}`);
    
    // First message
    console.log("\n1ï¸âƒ£ ì²« ë²ˆì§¸ ë©”ì‹œì§€ ì „ì†¡...");
    const first = await app.invoke(
      {
        messages: [new HumanMessage("hello i'm sangbaek")],
      },
      config,
    );
    console.log("âœ… ì²« ë²ˆì§¸ ì‘ë‹µ:", first.messages[first.messages.length - 1].content);
    
    // Second message (memory test)
    console.log("\n2ï¸âƒ£ ë‘ ë²ˆì§¸ ë©”ì‹œì§€ ì „ì†¡ (ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸)...");
    const second = await app.invoke(
      {
        messages: [new HumanMessage("what is my name?")],
      },
      config,
    );
    console.log("âœ… ë‘ ë²ˆì§¸ ì‘ë‹µ:", second.messages[second.messages.length - 1].content);
    
    // Get conversation history
    console.log("\nğŸ“š ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬:");
    const histories = app.getStateHistory(config);
    let messageCount = 0;
    for await (const state of histories) {
      const lastMessage = state.values.messages[state.values.messages.length - 1];
      if (lastMessage?.content) {
        messageCount++;
        console.log(`  ${messageCount}. ${lastMessage.content}`);
      }
    }
    
    // Get current state
    console.log("\nğŸ” í˜„ì¬ ìƒíƒœ:");
    const state = await app.getState(config);
    console.log("âœ… ìµœì¢… ë©”ì‹œì§€:", state.values.messages[state.values.messages.length - 1].content);
    
    console.log("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!");
    
  } catch (error) {
    console.error("âŒ ì˜¤ë¥˜ ë°œìƒ:", error);
    throw new Error("an error occurred while working");
  }
}

// Main function
async function main() {
  try {
    await work();
  } catch (error) {
    console.error("ë©”ì¸ í•¨ìˆ˜ ì˜¤ë¥˜:", error);
    process.exit(1);
  }
}

main();
